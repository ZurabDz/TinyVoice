{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e012eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from conformer.tokenizer import Tokenizer\n",
    "from conformer.dataset import batch_fn, ProcessAudioData, unpack_speech_data\n",
    "import grain\n",
    "from functools import partial\n",
    "from conformer.conformer_block import ConformerEncoder\n",
    "from conformer.config import ConformerConfig, TrainingConfig\n",
    "from flax import nnx\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d414c91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conformer_config = ConformerConfig()\n",
    "train_config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab8f7c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer.load('/home/penguin/data/tokenizer/tokenizer.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00f9ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_source = grain.sources.ArrayRecordDataSource('/home/penguin/data/packed_dataset/train/data.array_record')\n",
    "test_audio_source = grain.sources.ArrayRecordDataSource('/home/penguin/data/packed_dataset/test/data.array_record')\n",
    "tokenizer_batch_fn = partial(batch_fn, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4f6e73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_train_audio_dataset = grain.MapDataset.source(train_audio_source)\n",
    "map_test_audio_dataset = grain.MapDataset.source(test_audio_source)\n",
    "\n",
    "processed_train_dataset = (\n",
    "    map_train_audio_dataset\n",
    "    .shuffle(seed=42)\n",
    "    .map(ProcessAudioData(tokenizer))\n",
    "    .batch(batch_size=24, batch_fn=tokenizer_batch_fn)\n",
    ")\n",
    "\n",
    "processed_test_dataset = (\n",
    "    map_test_audio_dataset\n",
    "    .shuffle(seed=42)\n",
    "    .map(ProcessAudioData(tokenizer))\n",
    "    .batch(batch_size=24, batch_fn=tokenizer_batch_fn)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7118bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConformerEncoder(conformer_config, num_classes=42, rngs=nnx.Rngs(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d31ede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from conformer.train_utils import (\n",
    "    create_learning_rate_fn,\n",
    "    train_step,\n",
    "    eval_step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7db1049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule = create_learning_rate_fn(train_config.warmup_steps, conformer_config.encoder_dim)\n",
    "optimizer = nnx.Optimizer(\n",
    "    model,\n",
    "    optax.adamw(\n",
    "        learning_rate=lr_schedule,\n",
    "        b1=train_config.beta1,\n",
    "        b2=train_config.beta2,\n",
    "        weight_decay=train_config.weight_decay,\n",
    "    ),\n",
    "    wrt=nnx.Param\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e826df54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-21 13:26:37.734247: W external/xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 6.49GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-21 13:26:42.028775: W external/xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.21GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-09-21 13:26:44.998641: E external/xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng28{k2=3,k3=0} for conv (f32[24,256,735,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,256,737,66]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2025-09-21 13:26:45.185384: E external/xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.186813649s\n",
      "Trying algorithm eng28{k2=3,k3=0} for conv (f32[24,256,735,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,256,737,66]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2025-09-21 13:26:46.185520: E external/xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng1{k2=4,k3=0} for conv (f32[24,256,735,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,256,737,66]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2025-09-21 13:26:46.419414: E external/xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.233963746s\n",
      "Trying algorithm eng1{k2=4,k3=0} for conv (f32[24,256,735,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,256,737,66]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2025-09-21 13:26:47.419558: E external/xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng28{k2=4,k3=0} for conv (f32[24,256,735,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,256,737,66]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2025-09-21 13:26:47.675175: E external/xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.255689438s\n",
      "Trying algorithm eng28{k2=4,k3=0} for conv (f32[24,256,735,64]{3,2,1,0}, u8[0]{0}) custom-call(f32[24,256,737,66]{3,2,1,0}, f32[256,256,3,3]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convForward\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n"
     ]
    }
   ],
   "source": [
    "loss = train_step(model, optimizer, processed_train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "155d67ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758468431.782604  123388 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1041 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64b57ef1c7be44319eeb3938f771028d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training loop:   0%|          | 0/4615 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e5024ddc444b18a248a6c28fe881dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval loop:   0%|          | 0/243 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67863ed4df2f4419abdacee8b1640d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval loop:   0%|          | 0/243 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28e3725fbe744be09508840cadbe70ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval loop:   0%|          | 0/243 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f0f9103d854af0836d87c29d5d8ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval loop:   0%|          | 0/243 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m total_eval_loss_accumulator = \u001b[32m0\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m eval_batch \u001b[38;5;129;01min\u001b[39;00m tqdm(processed_test_dataset, desc=\u001b[33m'\u001b[39m\u001b[33meval loop\u001b[39m\u001b[33m'\u001b[39m, colour=\u001b[33m'\u001b[39m\u001b[33mblue\u001b[39m\u001b[33m'\u001b[39m, leave=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     eval_loss = \u001b[43meval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     total_eval_loss_accumulator += eval_loss\n\u001b[32m     30\u001b[39m avg_eval_loss = total_eval_loss_accumulator / \u001b[38;5;28mlen\u001b[39m(processed_test_dataset)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TinyVoice/.pixi/envs/default/lib/python3.12/site-packages/flax/nnx/transforms/compilation.py:431\u001b[39m, in \u001b[36mJitWrapped.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m graph.update_context(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    430\u001b[39m   pure_args, pure_kwargs = \u001b[38;5;28mself\u001b[39m._get_pure_args_kwargs(args, kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m431\u001b[39m   pure_args_out, pure_kwargs_out, pure_out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjitted_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43mpure_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpure_kwargs\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m   out = \u001b[38;5;28mself\u001b[39m._get_non_pure_out(pure_args_out, pure_kwargs_out, pure_out)\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/TinyVoice/.pixi/envs/default/lib/python3.12/site-packages/jax/_src/tree_util.py:1158\u001b[39m, in \u001b[36mregister_static.<locals>.<lambda>\u001b[39m\u001b[34m(obj, empty_iter_children)\u001b[39m\n\u001b[32m   1127\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Registers `cls` as a pytree with no leaves.\u001b[39;00m\n\u001b[32m   1128\u001b[39m \n\u001b[32m   1129\u001b[39m \u001b[33;03mInstances are treated as static by :func:`jax.jit`, :func:`jax.pmap`, etc. This can\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1155\u001b[39m \u001b[33;03m  Array(3, dtype=int32, weak_type=True)\u001b[39;00m\n\u001b[32m   1156\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1157\u001b[39m flatten = \u001b[38;5;28;01mlambda\u001b[39;00m obj: ((), obj)\n\u001b[32m-> \u001b[39m\u001b[32m1158\u001b[39m unflatten = \u001b[38;5;28;01mlambda\u001b[39;00m obj, empty_iter_children: obj\n\u001b[32m   1159\u001b[39m register_pytree_with_keys(\u001b[38;5;28mcls\u001b[39m, flatten, unflatten)\n\u001b[32m   1160\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from clu import metric_writers\n",
    "logdir = './metrics'\n",
    "\n",
    "writer = metric_writers.create_default_writer(logdir)\n",
    "total_loss_accumulator = 0\n",
    "\n",
    "\n",
    "n_steps_to_save_avg_train_loss = 20\n",
    "n_steps_for_eval = 100\n",
    "\n",
    "for step_count, batch in tqdm(enumerate(processed_train_dataset, 1),\n",
    "                               total=len(processed_train_dataset),\n",
    "                               desc=\"training loop\",\n",
    "                               colour=\"green\"):\n",
    "    \n",
    "    loss = train_step(model, optimizer, batch)\n",
    "    total_loss_accumulator += loss.item()\n",
    "\n",
    "    if step_count % n_steps_to_save_avg_train_loss == 0:\n",
    "        avg_loss = total_loss_accumulator / n_steps_to_save_avg_train_loss\n",
    "        writer.write_scalars(step_count, {'train_loss': avg_loss})\n",
    "        total_loss_accumulator = 0\n",
    "\n",
    "    if step_count % n_steps_for_eval == 0:\n",
    "        total_eval_loss_accumulator = 0\n",
    "        for eval_batch in tqdm(processed_test_dataset, desc='eval loop', colour='blue', leave=False):\n",
    "            eval_loss = eval_step(model, batch)\n",
    "            total_eval_loss_accumulator += eval_loss\n",
    "\n",
    "        avg_eval_loss = total_eval_loss_accumulator / len(processed_test_dataset)\n",
    "        writer.write_scalars(step_count, {'eval_loss': avg_eval_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d209b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
